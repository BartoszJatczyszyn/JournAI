# ğŸ¥ Garmin Health Data Analysis System

Kompletny system analizy danych zdrowotnych z urzÄ…dzeÅ„ Garmin z integracjÄ… PostgreSQL, dziennikiem osobistym i zaawansowanÄ… analitykÄ… AI.

## ğŸ“Š FunkcjonalnoÅ›ci

### âœ… Kompletna migracja danych Garmin:
- **959,911 rekordÃ³w** zdrowotnych w 9 tabelach
- **305,354 pomiarÃ³w tÄ™tna** co minutÄ™ (24/7)
- **268,844 pomiarÃ³w czÄ™stoÅ›ci oddechowej**
- **380,672 pomiarÃ³w stresu**
- **1,025 aktywnoÅ›ci sportowych** z peÅ‚nymi danymi
- **277 sesji snu** z detalowÄ… analizÄ…

### ğŸ“ Dziennik osobisty:
- **69 kolumn** do trackingu Å¼ycia
- NastrÃ³j, energia, stress (skale 1-5)
- OdÅ¼ywianie, suplementy, nawyki
- Korelacje z danymi Garmin

### ğŸ§  **NOWE! Zaawansowana Analityka AI:**
- **Korelacje wielowymiarowe** (Pearson, Spearman, Kendall)
- **Analiza klastrÃ³w** - automatyczne wykrywanie wzorcÃ³w zdrowotnych
- **Analiza temporalna** - wzorce tygodniowe i sezonowe
- **Analiza regeneracji** - kompleksowa ocena odzyskiwania siÅ‚
- **Analityka predykcyjna** - prognozy energii, snu i nastroju
- **Personalizowane rekomendacje** oparte na danych

### ğŸ”¬ Specjalistyczne moduÅ‚y analityczne:
- **Analiza snu**: efektywnoÅ›Ä‡, timing, wpÅ‚yw na wydajnoÅ›Ä‡
- **Analiza stresu**: wzorce godzinowe, triggery, regeneracja
- **Analiza aktywnoÅ›ci**: intensywnoÅ›Ä‡, konsystencja, korelacje z regeneracjÄ…

### ğŸ—ƒï¸ Zorganizowane tabele:
- `garmin_daily_summaries` - dzienne podsumowania (33 kolumny)
- `garmin_activities` - aktywnoÅ›ci sportowe (51 kolumn)
- `garmin_sleep_sessions` - sesje snu (21 kolumn)
- `daily_journal` - dziennik osobisty (69 kolumn)

## ğŸš€ Szybki start

1. **Konfiguracja bazy:**
   ```bash
   # Edytuj config.env z danymi PostgreSQL
   cp config.env.example config.env
   ```

2. **Instalacja zaleÅ¼noÅ›ci:**
   ```bash
   pip install -r Diary-AI-BE/requirements.txt
   ```

3. **Uruchomienie backendu:**
   ```bash
   # NOWY! Enhanced Backend z AI Analytics
   python scripts/start_enhanced_backend.py
   
   # Lub bezpoÅ›rednio
   cd Diary-AI-BE/scripts && python backend_api_enhanced.py
   
   # Backend Enhanced (zalecany)
   python scripts/start_enhanced_backend.py
   ```

4. **Dashboard:**
   OtwÃ³rz `Diary-AI-FE/simple_dashboard.html` w przeglÄ…darce

### ğŸ³ Alternatywa: uruchomienie przez Docker Compose

Najprostszy sposÃ³b aby kaÅ¼dy uruchomiÅ‚ backend + Postgres bez lokalnej instalacji zaleÅ¼noÅ›ci.

```bash
# Skopiuj zmienne (opcjonalnie)
cp .env.docker.example .env

# Uruchom stack (baza + backend)
docker compose up -d --build

# SprawdÅº logi
docker compose logs -f backend

# Przetestuj endpoint
curl http://localhost:5002/api/predictions/energy?days_ahead=3
```

SzczegÃ³Å‚y: zobacz `DOCKER_SETUP.md`.

#### Migrowanie danych do bazy w Å›rodowisku Docker

JeÅ›li chcesz wypeÅ‚niÄ‡ czystÄ… bazÄ™ danymi Garmin/journal:

1. Upewnij siÄ™, Å¼e stack dziaÅ‚a:
   ```bash
   docker compose up -d --build
   docker compose ps
   ```
2. WejdÅº do kontenera backend lub uruchom komendÄ™ bezpoÅ›rednio:
   ```bash
   # PeÅ‚na migracja (wszystkie tabele / zakresy)
   docker compose exec backend python run_migration.py --subset all

   # Lub migracje czÄ™Å›ciowe (przykÅ‚ady):
   docker compose exec backend python run_migration.py --subset daily
   docker compose exec backend python run_migration.py --subset sleep
   docker compose exec backend python run_migration.py --subset activities
   docker compose exec backend python run_migration.py --subset journal
   docker compose exec backend python run_migration.py --subset stats  # wyliczenia agregatÃ³w minutowych
   ```
3. Walidacja po migracji (przykÅ‚adowe zapytania):
   ```bash
   docker compose exec db psql -U diary_user -d diary -c "SELECT COUNT(*) FROM garmin_daily_summaries;"
   docker compose exec db psql -U diary_user -d diary -c "SELECT COUNT(*) FROM garmin_sleep_sessions;"
   docker compose exec db psql -U diary_user -d diary -c "SELECT COUNT(*) FROM daily_journal;"
   ```
4. Test endpointÃ³w po migracji:
   ```bash
   curl 'http://localhost:5002/api/analytics/enhanced/correlations?days=30' | head
   curl 'http://localhost:5002/api/predictions/energy?days_ahead=3'
   ```

BezpieczeÅ„stwo: plik `config.env` nie jest potrzebny wewnÄ…trz kontenera (zmienne przekazuje compose). JeÅ›li dodasz wÅ‚asny config â€“ nie commituj go do repo.

Przebudowa po zmianach migratora (`scripts/enhanced_migration.py`):
```bash
docker compose build backend
docker compose exec backend python run_migration.py --subset all
```

## ğŸ†• Enhanced Backend API - Zaawansowana Analityka

### ğŸ§  Zaawansowane endpointy analityczne:
- `/api/analytics/enhanced/comprehensive` - kompleksowa analiza AI
- `/api/analytics/enhanced/correlations` - korelacje wielowymiarowe
- `/api/analytics/enhanced/clusters` - analiza klastrÃ³w zdrowotnych
- `/api/analytics/enhanced/temporal-patterns` - wzorce temporalne
- `/api/analytics/enhanced/recovery` - analiza regeneracji

### ğŸ”¬ Specjalistyczne analizy:
- `/api/analytics/sleep/comprehensive` - kompleksowa analiza snu
- `/api/analytics/stress/comprehensive` - analiza wzorcÃ³w stresu
- `/api/analytics/activity/comprehensive` - analiza aktywnoÅ›ci

### ğŸ”® Analityka predykcyjna:
- `/api/predictions/energy` - prognozy poziomu energii
- `/api/predictions/sleep` - prognozy jakoÅ›ci snu
- `/api/predictions/mood` - prognozy nastroju
- `/api/predictions/comprehensive` - kompleksowe prognozy
- `/api/trends/health` - trendy zdrowotne

#### Parametry prognoz (days_ahead)
KaÅ¼dy endpoint predykcyjny przyjmuje parametr zapytania `days_ahead` (alias: `days`) okreÅ›lajÄ…cy horyzont prognozy.

Rekomendowane wartoÅ›ci:
- 1â€“7 dni: najwyÅ¼sza trafnoÅ›Ä‡ (modele RandomForest + cechy krÃ³tkoterminowe)
- 8â€“14 dni: akceptowalne, ale malejÄ…ca pewnoÅ›Ä‡ (confidence spada liniowo)
- >14 dni: moÅ¼liwe, lecz maÅ‚o wiarygodne (generowane wyÅ‚Ä…cznie ekstrapolacyjnie â€“ niezalecane)

KaÅ¼da pojedyncza prognoza zawiera:
```json
{
   "date": "2025-10-02",
   "predicted_value": 3.87,
   "confidence": 0.82
}
```
`confidence` maleje wraz z odlegÅ‚oÅ›ciÄ… dnia w horyzoncie oraz ocenÄ… jakoÅ›ci modelu (`confidence_level`: high / medium / low / very_low).

Fallback: Gdy zbyt maÅ‚o danych (<30 peÅ‚nych rekordÃ³w) model przeÅ‚Ä…cza siÄ™ na tryb bazowy (trend + Å›rednia z ostatnich wartoÅ›ci) i zwraca strukturÄ™ z `confidence_level = very_low`.

### ğŸ’¡ Personalizowane insights:
- `/api/insights/personalized` - spersonalizowane rekomendacje
- `/api/insights/optimization` - optymalizacja metryk zdrowotnych
- `/api/analytics/compare/periods` - porÃ³wnania okresÃ³w

### ğŸ› ï¸ Endpoint administracyjny (operacje ML)
- `POST /api/admin/models/retrain`
   - Usuwa zapisane artefakty modeli (`energy.joblib`, `sleep.joblib`, `mood.joblib`)
   - Modele zostanÄ… przebudowane leniwie przy nastÄ™pnym wywoÅ‚aniu endpointu predykcyjnego
   - Opcjonalne body JSON do selektywnej kasacji:
      ```json
      { "models": ["energy", "sleep"] }
      ```
   - PrzykÅ‚ad odpowiedzi:
      ```json
      {
         "status": "success",
         "removed": ["energy.joblib", "sleep.joblib"],
         "message": "Models deleted; they will be retrained on next prediction request."
      }
      ```

### ğŸ” WaÅ¼ne parametry zapytaÅ„ (query params)
| Obszar | Parametr | DomyÅ›lna | Zakres / Uwagi |
|--------|----------|----------|----------------|
| Enhanced analytics | `days` | 90 | 1â€“365 |
| Clusters | `clusters` | 3 | 2â€“15 (wiÄ™ksza liczba = wiÄ™ksze ryzyko szumu) |
| Recovery | `compare` | false | `true` dodaje poprzedni okres trendu |
| Period compare | `period1_days`, `period2_days` | 30 | 1â€“365 |
| Period compare | `offset_days` | 30 | odstÄ™p miÄ™dzy okresami |
| Predictions | `days_ahead` (`days`) | 7 | rekomendowane 1â€“14 |
| Insights optimization | `metric` | sleep_quality | dowolna nazwa metryki w zbiorze |

### â™»ï¸ TrwaÅ‚oÅ›Ä‡ i retraining modeli
Modele ML sÄ… zapisywane jako pliki `.joblib` w `Diary-AI-BE/scripts/analytics/models/` i sÄ… ignorowane przez Git (`.gitignore`).

Strategia:
- Przy starcie: prÃ³ba zaÅ‚adowania artefaktu; jeÅ›li niezgodny â€“ automatyczne usuniÄ™cie i retraining
- Przy bÅ‚Ä™dzie Å‚adowania (np. zmiana wersji scikit-learn): wymuszone kasowanie i ponowny trening
- Retraining nastÄ™puje tylko jeÅ›li model nie istnieje lub jest niekompatybilny (leniwe podejÅ›cie)

Confidence logic:
- Globalna jakoÅ›Ä‡ modelu (`confidence_level`) oparta o RÂ² (progi: 0.8 / 0.6 / 0.4)
- Per-dzieÅ„ `confidence` maleje liniowo do min. 0.5 przy koÅ„cu horyzontu

### ğŸ§ª PrzykÅ‚ady (curl)
```bash
# 3-dniowa prognoza energii
curl 'http://localhost:5002/api/predictions/energy?days_ahead=3'

# 14-dniowa prognoza snu (gÃ³rna granica rekomendacji)
curl 'http://localhost:5002/api/predictions/sleep?days_ahead=14'

# Kompleksowe prognozy (mood + energy + sleep)
curl 'http://localhost:5002/api/predictions/comprehensive?days_ahead=7'

# PorÃ³wnanie dwÃ³ch okresÃ³w (30 dni vs 30 dni z 30-dniowym offsetem)
curl 'http://localhost:5002/api/analytics/compare/periods?period1_days=30&period2_days=30&offset_days=30'

# Recovery z porÃ³wnaniem poprzedniego okresu
curl 'http://localhost:5002/api/analytics/enhanced/recovery?days=90&compare=true'

# Kasacja artefaktÃ³w modeli (wymuszenie retrainingu)
curl -X POST 'http://localhost:5002/api/admin/models/retrain' \
       -H 'Content-Type: application/json' \
       -d '{"models": ["energy", "sleep"]}'
```

### ğŸ’“ Monitoring w czasie rzeczywistym:
- **305,354 pomiarÃ³w tÄ™tna** co minutÄ™ (24/7)
- **380,672 pomiarÃ³w stresu** z kategoryzacjÄ…
- **268,844 pomiarÃ³w czÄ™stoÅ›ci oddechowej**
- **3,362 zdarzeÅ„ snu** z detalowÄ… analizÄ…
- **98 pomiarÃ³w wagi** z trendem

### ğŸ”— Standardowe endpointy API:
- `/api/heart-rate/daily/<date>` - dane tÄ™tna dla dnia
- `/api/stress/daily/<date>` - dane stresu z kategoryzacjÄ…
- `/api/respiratory-rate/daily/<date>` - czÄ™stoÅ›Ä‡ oddechowa
- `/api/weight/history` - historia wagi
- `/api/sleep/events/<date>` - zdarzenia podczas snu

## ğŸ“– Dokumentacja

- [Enhanced Analytics Documentation](docs/ENHANCED_ANALYTICS_DOCUMENTATION.md) - **NOWE! AI Analytics**
- [Przewodnik uÅ¼ytkownika](docs/USAGE_GUIDE.md)
- [Konfiguracja frontendu](docs/FRONTEND_SETUP.md)
- [Kompletny setup](docs/COMPLETE_SETUP_GUIDE.md)

## ğŸ”— PrzykÅ‚adowe analizy

```sql
-- Korelacja nastroju z aktywnoÅ›ciÄ…
SELECT d.mood, d.energy_level, g.steps, g.calories_total
FROM daily_journal d 
JOIN garmin_daily_summaries g ON d.day = g.day;

-- WpÅ‚yw snu na regeneracjÄ™
SELECT s.sleep_score, s.deep_sleep, g.rhr, d.sleep_quality_manual
FROM garmin_sleep_sessions s
JOIN garmin_daily_summaries g ON s.day = g.day
LEFT JOIN daily_journal d ON s.day = d.day;
```

## ğŸ§ª Testowanie Enhanced Analytics

```bash
# Test bezpoÅ›redni moduÅ‚Ã³w (kaÅ¼dy plik ma tryb main)
cd Diary-AI-BE/scripts && python enhanced_analytics_engine.py
cd Diary-AI-BE/scripts && python specialized_analytics.py
cd Diary-AI-BE/scripts && python predictive_analytics.py
```

## ğŸ“¦ Dodatkowe zaleÅ¼noÅ›ci dla Enhanced Analytics

```bash
# Instalacja pakietÃ³w ML/AI
pip install numpy scipy scikit-learn

# Lub automatycznie przy starcie
cd Diary-AI-BE/scripts && python start_enhanced_backend.py  # sprawdzi i zainstaluje
```

## ğŸ”§ Konfiguracja Enhanced Analytics

### Minimalne wymagania danych:
- **30+ dni** danych dziennych dla podstawowej analizy
- **60+ dni** dla analizy predykcyjnej
- **90+ dni** dla peÅ‚nej analizy trendÃ³w
- **1000+ pomiarÃ³w** tÄ™tna/stresu dla analizy wzorcÃ³w

### Porty serwerÃ³w:
- **Port 5002**: Enhanced Backend API (AI Analytics, domyÅ›nie uruchamiany)

## ğŸ§± Struktura i wzorce (SOLID)

SzczegÃ³Å‚y struktury projektu: zobacz PROJECT_STRUCTURE.md


- Warstwa services (Python):
  - `scripts/services/journal_service.py` â€“ operacje na `daily_journal`
  - `scripts/services/trends_service.py` â€“ zapytania trendÃ³w (sen, waga, nastrÃ³j)
  - `scripts/services/health_service.py` â€“ health check, status
- Endpointy Flask korzystajÄ… z serwisÃ³w (separacja odpowiedzialnoÅ›ci)
- WspÃ³lne utilsy: `scripts/utils.py`, `scripts/db.py`, `scripts/model_utils.py`

## ğŸ“Š Status projektu

âœ… **KOMPLETNY SYSTEM Z AI ANALYTICS GOTOWY DO UÅ»YCIA**
- Wszystkie dane Garmin zmigrowane
- Tabele zoptymalizowane i zorganizowane
- Dziennik osobisty zintegrowany
- API i dashboard dziaÅ‚ajÄ…
- **NOWE!** Zaawansowana analityka AI z machine learning
- **NOWE!** Analityka predykcyjna i personalizowane rekomendacje
- **NOWE!** Specjalistyczne moduÅ‚y analityczne
- Gotowy do zaawansowanych analiz zdrowotnych

## ğŸ” BezpieczeÅ„stwo i publikacja na GitHub

Przed publikacjÄ… upewnij siÄ™ Å¼e:
- NIE commitujesz pliku `config.env` (uÅ¼yj `config.env.example` jako szablonu)
- Modele i cache nie zawierajÄ… danych prywatnych
- Lokalna Å›cieÅ¼ka `HEALTH_DATA_PATH` nie wskazuje na prywatny katalog w repo

## ğŸ“‚ Folder `HealthData` â€“ co to jest i jak uÅ¼ywaÄ‡

`HealthData/` to **lokalny katalog ÅºrÃ³dÅ‚owy surowych danych Garmin** (eksport / zrzuty / pliki *.db / CSV), z ktÃ³rego migrator pobiera dane i Å‚aduje je do PostgreSQL.

### Dlaczego nie ma go w repo?
- Zawiera dane wraÅ¼liwe / prywatne (tÄ™tno, sen, stres, nawyki)
- Pliki binarne i bazy SQLite powiÄ™kszyÅ‚yby repo i utrudniÅ‚y historiÄ™
- Dane ÅºrÃ³dÅ‚owe powinny byÄ‡ odtwarzalne z prywatnego archiwum u uÅ¼ytkownika

### Jak wskazaÄ‡ Å›cieÅ¼kÄ™?
Ustaw zmiennÄ… Å›rodowiskowÄ… (lub wpis w `config.env`):
```
HEALTH_DATA_PATH=/absolute/path/do/HealthData
```
JeÅ›li nie ustawisz â€“ migrator sprÃ³buje uÅ¼yÄ‡ lokalnie `./HealthData` (i zaloguje ostrzeÅ¼enie gdy nie istnieje).

### Struktura oczekiwana (przykÅ‚ad)
```
HealthData/
   Sleep/                    # Pliki snu / JSON / CSV
   RHR/                      # Resting Heart Rate
   Weight/                   # Historia wagi
   DBs/                      # Bazy SQLite (garmin.db, garmin_activities.db itd.)
   Activities/               # (opcjonalnie) pliki aktywnoÅ›ci
   ...
```

### Jak sprawdziÄ‡ czy Å›cieÅ¼ka dziaÅ‚a
```bash
python Diary-AI-BE/run_migration.py --subset sleep
```
JeÅ›li katalog bÅ‚Ä™dny â€“ zobaczysz ostrzeÅ¼enie o fallbacku lub brak rekordÃ³w w tabeli docelowej.

### W Å›rodowisku Docker
- DomyÅ›lnie kontener backend uÅ¼ywa Å›cieÅ¼ki wewnÄ™trznej (jeÅ›li chciaÅ‚byÅ› uÅ¼yÄ‡ lokalnych surowych plikÃ³w, zamontuj je):
```yaml
   backend:
      volumes:
         - /lokalna/sciezka/HealthData:/app/HealthData:ro
      environment:
         HEALTH_DATA_PATH=/app/HealthData
```

### Dobre praktyki
- Nigdy nie commituj prawdziwego `HealthData/`
- JeÅ›li chcesz udostÄ™pniÄ‡ strukturÄ™, zrÃ³b pusty przykÅ‚ad typu `HealthData.example/` (bez realnych danych)
- Regularnie archiwizuj ÅºrÃ³dÅ‚o (zip + szyfrowanie) poza repo

### Szybka diagnostyka (skrypt wÅ‚asny)
MoÅ¼esz stworzyÄ‡ prosty checker (juÅ¼ masz `simple_check.py` / `test_fixed_migration.py`):
```bash
python simple_check.py
```
JeÅ›li wszystko ok â€“ zobaczysz âœ… przy podkatalogach (Sleep, RHR, Weight ...)


### Kroki publikacji (jeÅ›li tworzysz nowe repo)
```bash
git init
git add .
git commit -m "Initial project import"
git branch -M master
# utwÃ³rz repo na GitHub (lub uÅ¼yj istniejÄ…cego) i dodaj remote:
git remote add origin https://github.com/<twoj-user>/Journal-AI.git
git push -u origin master
```

### Aktualizacja istniejÄ…cego repo
```bash
git pull --rebase origin master
# wprowadÅº zmiany
git add .
git commit -m "<opis zmian>"
git push
```

### Regeneracja Å›rodowiska po klonowaniu
```bash
cp config.env.example config.env
pip install -r Diary-AI-BE/requirements.txt
python scripts/start_enhanced_backend.py
```

> JeÅ›li przypadkowo wypchniesz sekrety: natychmiast je zmieÅ„, usuÅ„ z historii (`git filter-repo` / `git filter-branch`) i force push.

---
*Ostatnia aktualizacja: 2025-09-27 - Enhanced Analytics v1.2 (prediction horizons, admin retrain doc)*
