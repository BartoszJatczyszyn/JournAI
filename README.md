# ğŸ¥ JournAI â€“ Garmin Health Data Analysis System

"JournAI" to nowa nazwa repozytorium (wczeÅ›niej roboczo: Diary-AI / Journal-AI). Nazwy katalogÃ³w `Diary-AI-BE/` i `Diary-AI-FE/` pozostajÄ… tymczasowo niezmienione (stabilne Å›cieÅ¼ki w skryptach). Przy ewentualnym ich refaktorze (np. na `journai-be/`, `journai-fe/`) naleÅ¼y zaktualizowaÄ‡: 
- odwoÅ‚ania w Dockerfile / docker-compose
- Å›cieÅ¼ki w README / DOCKER_SETUP.md / QUICK_START.md
- reguÅ‚y w `.gitignore`
- komendy w dokumentacji migracji

JeÅ›li chcesz juÅ¼ teraz zmieniÄ‡ remote po rename w GitHub: 
```
git remote set-url origin https://github.com/<twoj-user>/JournAI.git
```
albo przez SSH: 
```
git remote set-url origin git@github.com:<twoj-user>/JournAI.git
```

Kompletny system analizy danych zdrowotnych z urzÄ…dzeÅ„ Garmin z integracjÄ… PostgreSQL, dziennikiem osobistym i zaawansowanÄ… analitykÄ… AI.

## ğŸ“Š FunkcjonalnoÅ›ci

### âœ… Kompletna migracja danych Garmin:
- **959,911 rekordÃ³w** zdrowotnych w 9 tabelach
- **305,354 pomiarÃ³w tÄ™tna** co minutÄ™ (24/7)
- **268,844 pomiarÃ³w czÄ™stoÅ›ci oddechowej**
- **380,672 pomiarÃ³w stresu**
- **1,025 aktywnoÅ›ci sportowych** z peÅ‚nymi danymi
- **277 sesji snu** z detalowÄ… analizÄ…

### ğŸ“ Dziennik osobisty:
- **69 kolumn** do trackingu Å¼ycia
- NastrÃ³j, energia, stress (skale 1-5)
- OdÅ¼ywianie, suplementy, nawyki
- Korelacje z danymi Garmin

### ğŸ§  **NOWE! Zaawansowana Analityka AI:**
- **Korelacje wielowymiarowe** (Pearson, Spearman, Kendall)
- **Analiza klastrÃ³w** - automatyczne wykrywanie wzorcÃ³w zdrowotnych
- **Analiza temporalna** - wzorce tygodniowe i sezonowe
- **Analiza regeneracji** - kompleksowa ocena odzyskiwania siÅ‚
- **Analityka predykcyjna** - prognozy energii, snu i nastroju
- **Personalizowane rekomendacje** oparte na danych

### ğŸ”¬ Specjalistyczne moduÅ‚y analityczne:
- **Analiza snu**: efektywnoÅ›Ä‡, timing, wpÅ‚yw na wydajnoÅ›Ä‡
- **Analiza stresu**: wzorce godzinowe, triggery, regeneracja
- **Analiza aktywnoÅ›ci**: intensywnoÅ›Ä‡, konsystencja, korelacje z regeneracjÄ…

### ğŸ—ƒï¸ Zorganizowane tabele:
- `garmin_daily_summaries` - dzienne podsumowania (33 kolumny)
- `garmin_activities` - aktywnoÅ›ci sportowe (51 kolumn)
- `garmin_sleep_sessions` - sesje snu (21 kolumn)
- `daily_journal` - dziennik osobisty (69 kolumn)

## ğŸš€ Szybki start

1. **Konfiguracja bazy:**
   ```bash
   # Edytuj config.env z danymi PostgreSQL
   cp config.env.example config.env
   ```

2. **Instalacja zaleÅ¼noÅ›ci:**
   ```bash
   pip install -r Diary-AI-BE/requirements.txt
   ```

3. **Uruchomienie backendu:**
   ```bash
   # NOWY! Enhanced Backend z AI Analytics
   python scripts/start_enhanced_backend.py
   
   # Lub bezpoÅ›rednio
   cd Diary-AI-BE/scripts && python backend_api_enhanced.py
   
   # Backend Enhanced (zalecany)
   python scripts/start_enhanced_backend.py
   ```

4. **Dashboard:**
   OtwÃ³rz `Diary-AI-FE/simple_dashboard.html` w przeglÄ…darce

### ï¿½ Skrypty start/stop (lokalne Å›rodowisko)
W katalogu gÅ‚Ã³wnym sÄ… dostÄ™pne uproszczone skrypty:

```bash
./start_all.sh   # uruchamia backend (enhanced) i ewentualne procesy pomocnicze
./stop_all.sh    # zatrzymuje procesy backendu (wyszukujÄ…c dziaÅ‚ajÄ…ce PID)
```

Zastosowanie:
- Szybki restart podczas developmentu
- PewnoÅ›Ä‡, Å¼e nie zostanie â€wiszÄ…cyâ€ proces backendu rezerwujÄ…cy port 5002

JeÅ›li skrypt nie ma uprawnieÅ„ wykonywalnych:
```bash
chmod +x start_all.sh stop_all.sh
```

W Å›rodowisku Docker zamiast tego uÅ¼ywaj `docker compose up` / `down`.

### ï¿½ğŸ³ Alternatywa: uruchomienie przez Docker Compose

Najprostszy sposÃ³b aby kaÅ¼dy uruchomiÅ‚ backend + Postgres bez lokalnej instalacji zaleÅ¼noÅ›ci.

```bash
# Skopiuj zmienne (opcjonalnie)
cp .env.docker.example .env

# Uruchom stack (baza + backend)
docker compose up -d --build

# SprawdÅº logi
docker compose logs -f backend

# Przetestuj endpoint
curl http://localhost:5002/api/predictions/energy?days_ahead=3
```

SzczegÃ³Å‚y: zobacz `DOCKER_SETUP.md`.

#### Migrowanie danych do bazy w Å›rodowisku Docker

JeÅ›li chcesz wypeÅ‚niÄ‡ czystÄ… bazÄ™ danymi Garmin/journal:

1. Upewnij siÄ™, Å¼e stack dziaÅ‚a:
   ```bash
   docker compose up -d --build
   docker compose ps
   ```
2. WejdÅº do kontenera backend lub uruchom komendÄ™ bezpoÅ›rednio:
   ```bash
   # PeÅ‚na migracja (wszystkie tabele / zakresy)
   docker compose exec backend python run_migration.py --subset all

   # Lub migracje czÄ™Å›ciowe (przykÅ‚ady):
   docker compose exec backend python run_migration.py --subset daily
   docker compose exec backend python run_migration.py --subset sleep
   docker compose exec backend python run_migration.py --subset activities
   docker compose exec backend python run_migration.py --subset journal
   docker compose exec backend python run_migration.py --subset stats  # wyliczenia agregatÃ³w minutowych
   ```
3. Walidacja po migracji (przykÅ‚adowe zapytania):
   ```bash
   docker compose exec db psql -U diary_user -d diary -c "SELECT COUNT(*) FROM garmin_daily_summaries;"
   docker compose exec db psql -U diary_user -d diary -c "SELECT COUNT(*) FROM garmin_sleep_sessions;"
   docker compose exec db psql -U diary_user -d diary -c "SELECT COUNT(*) FROM daily_journal;"
   ```
4. Test endpointÃ³w po migracji:
   ```bash
   curl 'http://localhost:5002/api/analytics/enhanced/correlations?days=30' | head
   curl 'http://localhost:5002/api/predictions/energy?days_ahead=3'
   ```

BezpieczeÅ„stwo: plik `config.env` nie jest potrzebny wewnÄ…trz kontenera (zmienne przekazuje compose). JeÅ›li dodasz wÅ‚asny config â€“ nie commituj go do repo.

Przebudowa po zmianach migratora (`scripts/enhanced_migration.py`):
```bash
docker compose build backend
docker compose exec backend python run_migration.py --subset all
```

## ğŸ†• Enhanced Backend API - Zaawansowana Analityka

### ğŸ§  Zaawansowane endpointy analityczne:
- `/api/analytics/enhanced/comprehensive` - kompleksowa analiza AI
- `/api/analytics/enhanced/correlations` - korelacje wielowymiarowe
- `/api/analytics/enhanced/clusters` - analiza klastrÃ³w zdrowotnych
- `/api/analytics/enhanced/temporal-patterns` - wzorce temporalne
- `/api/analytics/enhanced/recovery` - analiza regeneracji

### ğŸ”¬ Specjalistyczne analizy:
- `/api/analytics/sleep/comprehensive` - kompleksowa analiza snu
- `/api/analytics/stress/comprehensive` - analiza wzorcÃ³w stresu
- `/api/analytics/activity/comprehensive` - analiza aktywnoÅ›ci

### ğŸ”® Analityka predykcyjna:
- `/api/predictions/energy` - prognozy poziomu energii
- `/api/predictions/sleep` - prognozy jakoÅ›ci snu
- `/api/predictions/mood` - prognozy nastroju
- `/api/predictions/comprehensive` - kompleksowe prognozy
- `/api/trends/health` - trendy zdrowotne

#### Parametry prognoz (days_ahead)
KaÅ¼dy endpoint predykcyjny przyjmuje parametr zapytania `days_ahead` (alias: `days`) okreÅ›lajÄ…cy horyzont prognozy.

Rekomendowane wartoÅ›ci:
- 1â€“7 dni: najwyÅ¼sza trafnoÅ›Ä‡ (modele RandomForest + cechy krÃ³tkoterminowe)
- 8â€“14 dni: akceptowalne, ale malejÄ…ca pewnoÅ›Ä‡ (confidence spada liniowo)
- >14 dni: moÅ¼liwe, lecz maÅ‚o wiarygodne (generowane wyÅ‚Ä…cznie ekstrapolacyjnie â€“ niezalecane)

KaÅ¼da pojedyncza prognoza zawiera:
```json
{
   "date": "2025-10-02",
   "predicted_value": 3.87,
   "confidence": 0.82
}
```
`confidence` maleje wraz z odlegÅ‚oÅ›ciÄ… dnia w horyzoncie oraz ocenÄ… jakoÅ›ci modelu (`confidence_level`: high / medium / low / very_low).

Fallback: Gdy zbyt maÅ‚o danych (<30 peÅ‚nych rekordÃ³w) model przeÅ‚Ä…cza siÄ™ na tryb bazowy (trend + Å›rednia z ostatnich wartoÅ›ci) i zwraca strukturÄ™ z `confidence_level = very_low`.

### ğŸ’¡ Personalizowane insights:
- `/api/insights/personalized` - spersonalizowane rekomendacje
- `/api/insights/optimization` - optymalizacja metryk zdrowotnych
- `/api/analytics/compare/periods` - porÃ³wnania okresÃ³w

### ğŸ› ï¸ Endpoint administracyjny (operacje ML)
- `POST /api/admin/models/retrain`
   - Usuwa zapisane artefakty modeli (`energy.joblib`, `sleep.joblib`, `mood.joblib`)
   - Modele zostanÄ… przebudowane leniwie przy nastÄ™pnym wywoÅ‚aniu endpointu predykcyjnego
   - Opcjonalne body JSON do selektywnej kasacji:
      ```json
      { "models": ["energy", "sleep"] }
      ```
   - PrzykÅ‚ad odpowiedzi:
      ```json
      {
         "status": "success",
         "removed": ["energy.joblib", "sleep.joblib"],
         "message": "Models deleted; they will be retrained on next prediction request."
      }
      ```

### ğŸ” WaÅ¼ne parametry zapytaÅ„ (query params)
| Obszar | Parametr | DomyÅ›lna | Zakres / Uwagi |
|--------|----------|----------|----------------|
| Enhanced analytics | `days` | 90 | 1â€“365 |
| Clusters | `clusters` | 3 | 2â€“15 (wiÄ™ksza liczba = wiÄ™ksze ryzyko szumu) |
| Recovery | `compare` | false | `true` dodaje poprzedni okres trendu |
| Period compare | `period1_days`, `period2_days` | 30 | 1â€“365 |
| Period compare | `offset_days` | 30 | odstÄ™p miÄ™dzy okresami |
| Predictions | `days_ahead` (`days`) | 7 | rekomendowane 1â€“14 |
| Insights optimization | `metric` | sleep_quality | dowolna nazwa metryki w zbiorze |

### â™»ï¸ TrwaÅ‚oÅ›Ä‡ i retraining modeli
Modele ML sÄ… zapisywane jako pliki `.joblib` w `Diary-AI-BE/scripts/analytics/models/` i sÄ… ignorowane przez Git (`.gitignore`).

Strategia:
- Przy starcie: prÃ³ba zaÅ‚adowania artefaktu; jeÅ›li niezgodny â€“ automatyczne usuniÄ™cie i retraining
- Przy bÅ‚Ä™dzie Å‚adowania (np. zmiana wersji scikit-learn): wymuszone kasowanie i ponowny trening
- Retraining nastÄ™puje tylko jeÅ›li model nie istnieje lub jest niekompatybilny (leniwe podejÅ›cie)

Confidence logic:
- Globalna jakoÅ›Ä‡ modelu (`confidence_level`) oparta o RÂ² (progi: 0.8 / 0.6 / 0.4)
- Per-dzieÅ„ `confidence` maleje liniowo do min. 0.5 przy koÅ„cu horyzontu

### ğŸ§ª PrzykÅ‚ady (curl)
```bash
# 3-dniowa prognoza energii
curl 'http://localhost:5002/api/predictions/energy?days_ahead=3'

# 14-dniowa prognoza snu (gÃ³rna granica rekomendacji)
curl 'http://localhost:5002/api/predictions/sleep?days_ahead=14'

# Kompleksowe prognozy (mood + energy + sleep)
curl 'http://localhost:5002/api/predictions/comprehensive?days_ahead=7'

# PorÃ³wnanie dwÃ³ch okresÃ³w (30 dni vs 30 dni z 30-dniowym offsetem)
curl 'http://localhost:5002/api/analytics/compare/periods?period1_days=30&period2_days=30&offset_days=30'

# Recovery z porÃ³wnaniem poprzedniego okresu
curl 'http://localhost:5002/api/analytics/enhanced/recovery?days=90&compare=true'

# Kasacja artefaktÃ³w modeli (wymuszenie retrainingu)
curl -X POST 'http://localhost:5002/api/admin/models/retrain' \
       -H 'Content-Type: application/json' \
       -d '{"models": ["energy", "sleep"]}'
```

### ğŸ’“ Monitoring w czasie rzeczywistym:
- **305,354 pomiarÃ³w tÄ™tna** co minutÄ™ (24/7)
- **380,672 pomiarÃ³w stresu** z kategoryzacjÄ…
- **268,844 pomiarÃ³w czÄ™stoÅ›ci oddechowej**
- **3,362 zdarzeÅ„ snu** z detalowÄ… analizÄ…
- **98 pomiarÃ³w wagi** z trendem

### ğŸ”— Standardowe endpointy API:
- `/api/heart-rate/daily/<date>` - dane tÄ™tna dla dnia
- `/api/stress/daily/<date>` - dane stresu z kategoryzacjÄ…
- `/api/respiratory-rate/daily/<date>` - czÄ™stoÅ›Ä‡ oddechowa
- `/api/weight/history` - historia wagi
- `/api/sleep/events/<date>` - zdarzenia podczas snu

  - `scripts/services/trends_service.py` â€“ zapytania trendÃ³w (sen, waga, nastrÃ³j)

## \ud83d\ude80 Szybki start

Poni\u017cej znajdziesz najprostszy, przetestowany przep\u0142yw uruchomienia: backend (Postgres + Python API) w Dockerze oraz frontend lokalnie przez npm (u\u017cyteczne podczas developmentu).

1) Uruchom backend + baz\u0119 (Docker)

```bash
# (opcjonalnie) skopiuj przyk\u0142adowe zmienne do pliku .env
cp .env.docker.example .env || true

# Z katalogu root repo uruchom stack (Postgres + backend)
docker compose up -d --build

# Podgl\u0105d log\u00f3w backendu
docker compose logs -f backend
```

Backend domy\u015blnie nas\u0142uchuje na: http://localhost:5002

2) Uruchom frontend lokalnie (oddzielnie, npm)

```bash
# Przejd\u017a do folderu z frontendem React
cd Diary-AI-FE/frontend-react

# Zainstaluj zale\u017cno\u015bci (macOS / zsh)
npm install

# Uruchom frontend dev server
npm start
```

Frontend dev server uruchomi sie domy\u015blnie na: http://localhost:3000 i ma ustawiony "proxy" do backendu `http://localhost:5002` (zdefiniowane w `Diary-AI-FE/frontend-react/package.json`), dzi\u0119ki czemu wywo\u0142ania API z przegl\u0105darki b\u0119d\u0105 kierowane do lokalnego backendu.

3) Alternatywy

- Je\u015bli wolisz uruchomi\u0107 backend lokalnie bez Dockera:

```bash
cp config.env.example config.env
pip install -r Diary-AI-BE/requirements.txt
python scripts/start_enhanced_backend.py
```

- Je\u015bli chcesz serwowa\u0107 frontend statycznie w Dockerze, u\u017cyj skryptu `./start_fresh_docker.sh` (uruchomi tymczasowy nginx by podpi\u0107 zawarto\u015b\u0107 `Diary-AI-FE`), lub zbuduj frontend `npm run build` i zamontuj `build/` do kontenera nginx.

4) Testy zdrowia

```bash
# backend health
curl http://localhost:5002/api/health

# przyk\u0142adowy endpoint (analytics)
curl 'http://localhost:5002/api/predictions/energy?days_ahead=3'
```

Uwagi:
- Port backendu: 5002
- Port frontend dev servera: 3000
- Upewnij si\u0119, \u017ce masz Node.js w wersji zgodnej z `Diary-AI-FE/frontend-react/package.json` (zalecane: Node >=18.18.0 lub >=20)

### Skrypty start/stop (lokalne)
W katalogu g\u0142\u00f3wnym s\u0105 dost\u0119pne uproszczone skrypty:

```bash
./start_all.sh   # uruchamia backend (enhanced) i ewentualne procesy pomocnicze
./stop_all.sh    # zatrzymuje procesy backendu (wariant lokalny)
```

Je\u015bli skrypt nie ma uprawnie\u0144 wykonywalnych:

```bash
chmod +x start_all.sh stop_all.sh
```
âœ… **KOMPLETNY SYSTEM Z AI ANALYTICS GOTOWY DO UÅ»YCIA**
- Wszystkie dane Garmin zmigrowane
- Tabele zoptymalizowane i zorganizowane
- Dziennik osobisty zintegrowany
- API i dashboard dziaÅ‚ajÄ…
- **NOWE!** Zaawansowana analityka AI z machine learning
- **NOWE!** Analityka predykcyjna i personalizowane rekomendacje
- **NOWE!** Specjalistyczne moduÅ‚y analityczne
- Gotowy do zaawansowanych analiz zdrowotnych

## ğŸ” BezpieczeÅ„stwo i publikacja na GitHub

Przed publikacjÄ… upewnij siÄ™ Å¼e:
- NIE commitujesz pliku `config.env` (uÅ¼yj `config.env.example` jako szablonu)
- Modele i cache nie zawierajÄ… danych prywatnych
- Lokalna Å›cieÅ¼ka `HEALTH_DATA_PATH` nie wskazuje na prywatny katalog w repo

## ğŸ§© Migracja nowych danych (skrÃ³t)

SzczegÃ³Å‚owa instrukcja: patrz AI/docs/MANUAL_MIGRATION.md

NajkrÃ³tsza Å›cieÅ¼ka (Docker):
```bash
cd AI
docker compose up -d --build
# ZamontowaÅ‚em juÅ¼ lokalny HealthData do kontenera backend w docker-compose.yml
# Uruchom peÅ‚nÄ… migracjÄ™:
docker compose exec backend python - <<'PY'
from enhanced_migration import EnhancedGarminMigrator
m=EnhancedGarminMigrator()
m.migrate_sleep_data(); m.migrate_rhr_data(); m.migrate_daily_summary_data(); m.migrate_heart_rate_data(); m.migrate_respiratory_rate_data(); m.migrate_activities_data()
print('âœ… Migracja zakoÅ„czona')
PY
# lub:
# docker compose exec backend python run_migration.py
```

Wyniki sprawdzisz m.in. tak:
```bash
docker compose exec db psql -U diary_user -d diary -c "SELECT COUNT(*) FROM garmin_sleep_sessions;"
docker compose exec db psql -U diary_user -d diary -c "SELECT COUNT(*) FROM garmin_activities;"
```

JeÅ›li nie chcesz Dockera:
```bash
cd AI
pip install -r requirements.txt
python setup_migration.py
python enhanced_migration.py
```

## ğŸ“‚ Folder `HealthData` â€“ co to jest i jak uÅ¼ywaÄ‡

`HealthData/` to **lokalny katalog ÅºrÃ³dÅ‚owy surowych danych Garmin** (eksport / zrzuty / pliki *.db / CSV), z ktÃ³rego migrator pobiera dane i Å‚aduje je do PostgreSQL.

### Dlaczego nie ma go w repo?
- Zawiera dane wraÅ¼liwe / prywatne (tÄ™tno, sen, stres, nawyki)
- Pliki binarne i bazy SQLite powiÄ™kszyÅ‚yby repo i utrudniÅ‚y historiÄ™
- Dane ÅºrÃ³dÅ‚owe powinny byÄ‡ odtwarzalne z prywatnego archiwum u uÅ¼ytkownika

### Jak wskazaÄ‡ Å›cieÅ¼kÄ™?
Ustaw zmiennÄ… Å›rodowiskowÄ… (lub wpis w `config.env`):
```
HEALTH_DATA_PATH=/absolute/path/do/HealthData
```
JeÅ›li nie ustawisz â€“ migrator sprÃ³buje uÅ¼yÄ‡ lokalnie `./HealthData` (i zaloguje ostrzeÅ¼enie gdy nie istnieje).

### Struktura oczekiwana (przykÅ‚ad)
```
HealthData/
   Sleep/                    # Pliki snu / JSON / CSV
   RHR/                      # Resting Heart Rate
   Weight/                   # Historia wagi
   DBs/                      # Bazy SQLite (garmin.db, garmin_activities.db itd.)
   Activities/               # (opcjonalnie) pliki aktywnoÅ›ci
   ...
```

### Jak sprawdziÄ‡ czy Å›cieÅ¼ka dziaÅ‚a
```bash
python Diary-AI-BE/run_migration.py --subset sleep
```
JeÅ›li katalog bÅ‚Ä™dny â€“ zobaczysz ostrzeÅ¼enie o fallbacku lub brak rekordÃ³w w tabeli docelowej.

### W Å›rodowisku Docker
- DomyÅ›lnie kontener backend uÅ¼ywa Å›cieÅ¼ki wewnÄ™trznej (jeÅ›li chciaÅ‚byÅ› uÅ¼yÄ‡ lokalnych surowych plikÃ³w, zamontuj je):
```yaml
   backend:
      volumes:
         - /lokalna/sciezka/HealthData:/app/HealthData:ro
      environment:
         HEALTH_DATA_PATH=/app/HealthData
```

### Dobre praktyki
- Nigdy nie commituj prawdziwego `HealthData/`
- JeÅ›li chcesz udostÄ™pniÄ‡ strukturÄ™, zrÃ³b pusty przykÅ‚ad typu `HealthData.example/` (bez realnych danych)
- Regularnie archiwizuj ÅºrÃ³dÅ‚o (zip + szyfrowanie) poza repo

### Szybka diagnostyka (skrypt wÅ‚asny)
MoÅ¼esz stworzyÄ‡ prosty checker (juÅ¼ masz `simple_check.py` / `test_fixed_migration.py`):
```bash
python simple_check.py
```
JeÅ›li wszystko ok â€“ zobaczysz âœ… przy podkatalogach (Sleep, RHR, Weight ...)


### Kroki publikacji (jeÅ›li tworzysz nowe repo)
```bash
git init
git add .
git commit -m "Initial project import"
git branch -M master
# utwÃ³rz repo na GitHub (lub uÅ¼yj istniejÄ…cego) i dodaj remote:
git remote add origin https://github.com/<twoj-user>/JournAI.git
git push -u origin master
```

### Aktualizacja istniejÄ…cego repo
```bash
git pull --rebase origin master
# wprowadÅº zmiany
git add .
git commit -m "<opis zmian>"
git push
```

### Regeneracja Å›rodowiska po klonowaniu
```bash
cp config.env.example config.env
pip install -r Diary-AI-BE/requirements.txt
python scripts/start_enhanced_backend.py
```

> JeÅ›li przypadkowo wypchniesz sekrety: natychmiast je zmieÅ„, usuÅ„ z historii (`git filter-repo` / `git filter-branch`) i force push.

---
*Ostatnia aktualizacja: 2025-09-27 - Enhanced Analytics v1.2.1 (rename repo -> JournAI, instrukcje aktualizacji remote)*
